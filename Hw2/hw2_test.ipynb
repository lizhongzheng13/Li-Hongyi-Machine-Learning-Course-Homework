{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-22T10:41:32.231437Z",
     "start_time": "2025-03-22T10:41:32.227858Z"
    }
   },
   "source": [
    "import os\n",
    "import gc  #回收内存，节约资源\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from 深度学习入门.测试环境 import device"
   ],
   "outputs": [],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T10:41:32.252874Z",
     "start_time": "2025-03-22T10:41:32.249572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"设置随机种子\"\"\"\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ],
   "id": "134e2125daaeea9f",
   "outputs": [],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T10:41:32.263967Z",
     "start_time": "2025-03-22T10:41:32.261051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"读取pt文件---一段pt文件就是一段语音（特征）\"\"\"\n",
    "\n",
    "\n",
    "def load_features(path):\n",
    "    features = torch.load(path)\n",
    "    return features  #读取的pt文件的内容是张量(由t个39维的MFCC向量构成（简单理解就是：t个30维的帧）)"
   ],
   "id": "fbf3a3203a4ae4fc",
   "outputs": [],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T10:41:32.275967Z",
     "start_time": "2025-03-22T10:41:32.271887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"拼接frame\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "传入的参数：\n",
    "x[2],n=1\n",
    "    right=x[2][-1].repeat(1,1)=x[2][-1]   (第二组的最后一个帧)#注意我们传入的是第二组的x，所以这个操作的x[-1]也是属于第二组的\n",
    "    left=x[2][1:]   (第二组从标号为1的帧开始，所有的帧)\n",
    "    cat((x[2][1:],x[2][-1]),dim=0)\n",
    "x[0],n=-1\n",
    "    left=x[0][0].repeat(1,1)=x[0][0]\n",
    "    right=x[0][:-1]    (第零组的除了最后一个帧以外的其他帧)\n",
    "    cat((x[0][0],x[0][:-1]),dim=0)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def shift(x, n):\n",
    "    if n < 0:\n",
    "        left = x[0].repeat(-n, 1)\n",
    "        right = x[:n]\n",
    "    elif n > 0:\n",
    "        right = x[-1].repeat(n, 1)\n",
    "        left = x[n:]\n",
    "    else:\n",
    "        return x\n",
    "    return torch.cat((left, right), dim=0)"
   ],
   "id": "902556f675d08d2",
   "outputs": [],
   "execution_count": 227
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2ecd92da278c13cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T10:41:32.289960Z",
     "start_time": "2025-03-22T10:41:32.284920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "为了提高预测的准确率，进行左右帧的拼接\n",
    "拼接frame\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "x:[T,39]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def concat_features(x, concat_num):\n",
    "    #x:t个39维的MFCC向量构成的\n",
    "    #concat_num:拼接的数目（多少个帧需要拼接在一起）\n",
    "    assert concat_num % 2 == 1  #需要是奇数，因为需要左边和右边都进行拼接\n",
    "    #特殊情况:只有一个帧，就不用进行拼接\n",
    "    if concat_num < 2:\n",
    "        return x\n",
    "\n",
    "    seq_len = x.size(0)  #frame的个数\n",
    "    features_dim = x.size(1)  #每个frame的维度--39\n",
    "\n",
    "    x = x.repeat(1, concat_num)  #沿着第一维（即竖直方向重复了concat_num次）\n",
    "    \"\"\"\n",
    "    假设concat_num=3\n",
    "    seq_len=T,features_dim=39\n",
    "    view:[seq_len, concat_num, features_dim]   重构  [T,3,39]\n",
    "    permute:[concat_num,seq_len,features_dim]        [3,T,39]\n",
    "    [组号，帧序号，帧内数据序号]\n",
    "    \"\"\"\n",
    "    # concat_num: 代表每个时间步上，我们拼接了多少个相邻的帧（包括当前帧）\n",
    "    x = x.view(seq_len, concat_num, features_dim).permute(1, 0, 2)\n",
    "\n",
    "    mid = (concat_num // 2)  #取中间帧\n",
    "    \"\"\"\n",
    "    mid=3//2=1\n",
    "    r_idx=range(1,2)=1 #左闭右开\n",
    "    \n",
    "    x[2,:]=shift(x[2],1)\n",
    "    x[0,:]=shift(x[0],-1)\n",
    "    \"\"\"\n",
    "\n",
    "    for r_idx in range(1, mid + 1):\n",
    "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
    "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
    "    \"\"\"[seq_len,concat_num,features_dim]=[T,3,39]\"\"\"\n",
    "    return x.permute(1, 0, 2).view(seq_len,\n",
    "                                   concat_num * features_dim)  #seq_len向量个数，concat_num * features_dim：将拼接在一起的相邻帧的所有特征维度加起来得到的总维度"
   ],
   "id": "45c95e789b02299a",
   "outputs": [],
   "execution_count": 228
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T10:41:32.306071Z",
     "start_time": "2025-03-22T10:41:32.297780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"预处理\"\"\"\n",
    "\"\"\"\n",
    "split:读取保存了文件名的文本文档；区分当前的数据是测试集还是非测试集\n",
    "feat_dir:pt文件保存路径\n",
    "phone_path:3个文本文档所在的路径\n",
    "concat_nframes:多少个帧拼接在一起\n",
    "train_ratio=0.8:trian和val数据集的比例\n",
    "train_val_seed:随机种子数\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, train_val_seed=1999):\n",
    "    class_num = 41  #音素41个类别\n",
    "    mode = 'train' if (split == 'train' or split == 'val') else 'test'\n",
    "\n",
    "    label_dict = {}\n",
    "    if mode != 'test':\n",
    "        phone_file = open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines()  #逐行读取\n",
    "        for line in phone_file:\n",
    "            line = line.strip('\\n').split(' ')  #将换行符删除，使用空格进行隔开\n",
    "            label_dict[line[0]] = [int(p) for p in line[1:]]  #第零个元素作为字典中的key,其余的作为value\n",
    "            # 展开形式\n",
    "            # temp = []\n",
    "            # for p in line[1:]:\n",
    "            #     temp.append(int(p))\n",
    "    \"\"\"划分数据集\"\"\"\n",
    "    if split == 'train' or split == 'val':\n",
    "        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
    "        random.seed(train_val_seed)\n",
    "        random.shuffle(usage_list)\n",
    "        precent = int(len(usage_list) * train_ratio)  #划分的索引\n",
    "        if split == 'train':\n",
    "            usage_list = usage_list[:precent]\n",
    "        elif split == 'val':\n",
    "            usage_list = usage_list[precent:]\n",
    "    elif split == 'test':\n",
    "        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid \\'split\\' argument for dataset: PhoneDataset!\")\n",
    "\n",
    "    usage_list = [line.strip('\\n') for line in usage_list]  #删除换行符\n",
    "    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(\n",
    "        len(usage_list)))  #类别，当前的数据集，语音文件\n",
    "    max_len = 5000000\n",
    "    x = torch.empty(max_len, 39 * concat_nframes)  #concat_nframes：帧数\n",
    "    if mode != 'test':  #训练或验证环节需要用到label值\n",
    "        y = torch.empty(max_len, dtype=torch.long)\n",
    "\n",
    "    idx = 0\n",
    "    for i, fname in tqdm(enumerate(usage_list)):  #usage_list：保存的文件名 #enumerate相当于给数据加上索引\n",
    "        feat = load_features(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
    "        cur_len = len(feat)  #当前pt文件有多少个帧构成的\n",
    "        feat = concat_features(feat, concat_nframes)  #拼接帧\n",
    "        if mode != 'test':\n",
    "            label = torch.LongTensor(label_dict[fname])\n",
    "\n",
    "        x[idx: idx + cur_len] = feat\n",
    "\n",
    "        if mode != 'test':\n",
    "            y[idx: idx + cur_len] = label\n",
    "\n",
    "        idx += cur_len\n",
    "    x = x[:idx, :]\n",
    "    if mode != 'test':\n",
    "        y = y[:idx]\n",
    "    print(f'[INFO] {split} set')\n",
    "    print(x.shape)\n",
    "    if mode != 'test':\n",
    "        print(y.shape)\n",
    "        return x, y\n",
    "    else:\n",
    "        return x"
   ],
   "id": "55902fafa9e1e116",
   "outputs": [],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T10:41:32.318002Z",
     "start_time": "2025-03-22T10:41:32.313944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Dateset\"\"\"\n",
    "\n",
    "\n",
    "class LibriDataset(Dataset):\n",
    "    def __init__(self, x, y=None):\n",
    "        self.feature = x\n",
    "        if y is not None:\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.feature[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.feature[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature)"
   ],
   "id": "8cf8bd6b2d67be36",
   "outputs": [],
   "execution_count": 230
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T10:41:32.332528Z",
     "start_time": "2025-03-22T10:41:32.327359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Model\"\"\"\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "*args：表示传入不定个数的参数\n",
    "for _ in range(hidden_layers): #=填充多少个BasicBlock\n",
    "    temp.append([BasicBlock(hidden_dim, hidden_dim)])\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=41, hidden_dim=256, hidden_layers=1):  #hidden_layers=1隐藏层的个数\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            BasicBlock(input_dim, hidden_dim),  #输入层\n",
    "            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],  #隐藏层\n",
    "            nn.Linear(hidden_dim, output_dim)  #输出层\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ],
   "id": "c8167c356a618f67",
   "outputs": [],
   "execution_count": 231
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T10:41:32.344340Z",
     "start_time": "2025-03-22T10:41:32.341155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''参数定义'''\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "concat_nframes = 3  #多少帧拼接在一起。必须为奇数个，n=2k+1\n",
    "train_ratio = 0.8\n",
    "\n",
    "config = {\n",
    "    'seed': 0,\n",
    "    'batch_size': 512,\n",
    "    'n_epoch': 5,\n",
    "    'learning_rate': 0.0001,\n",
    "    'model_path': '/model.ckpt'\n",
    "}\n",
    "\n",
    "input_dim = 39 * concat_nframes  #拼接后的一个帧的维度\n",
    "hidden_layers = 3\n",
    "hidden_dim = 256"
   ],
   "id": "6c0678d19e0c03a0",
   "outputs": [],
   "execution_count": 232
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T10:41:32.360516Z",
     "start_time": "2025-03-22T10:41:32.352552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''训练过程'''\n",
    "\n",
    "\n",
    "def train_process(train_set, val_set, train_loader, val_loader, config, model, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "    best_acc = 0.0\n",
    "    n_epoch = config['n_epoch']\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "        '''训练模式'''\n",
    "        model.train()\n",
    "        for i, batch in enumerate(tqdm(train_loader)):\n",
    "            '''batch:dataloader中一个批次的数据，以及对应的labels'''\n",
    "            features, labels = batch\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            '''torch.max会返回两个值，具体的value，以及value所在的index'''\n",
    "            _, train_pred = torch.max(outputs, dim=1)  #得到可能性最高的类别编号 #dim=1比较行\n",
    "            train_acc += (train_pred.detach() == labels.detach()).sum().item()  #detach()阻断反向传播，比较数据大小\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        '''验证模式'''\n",
    "\n",
    "        if (len(val_set) > 0):\n",
    "            val_acc = 0.0\n",
    "            val_loss = 0.0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for i, batch in enumerate(tqdm(val_loader)):\n",
    "                    features, labels = batch\n",
    "                    features = features.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(features)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, val_pred = torch.max(outputs, dim=1)\n",
    "                    val_acc += (val_pred.cpu() == labels.cpu()).sum().item()\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                print('[{:03d}/{:03d}] Train Acc : {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss : {:3.6f}'.format(\n",
    "                    epoch + 1, n_epoch, train_acc / len(train_set), train_loss / len(train_loader),\n",
    "                    val_acc / len(val_set), val_loss / len(val_loader)))\n",
    "\n",
    "                #保存最优模型\n",
    "                if val_acc > best_acc:\n",
    "                    best_acc = val_acc\n",
    "                    torch.save(model.state_dict(), config['model_path'])\n",
    "                    print(\"saving model with acc:{:3.6}\".format(best_acc / len(train_loader)))\n",
    "        else:\n",
    "            print(\"[{:03d}/{:03d}] Train Acc : {:3.6f} Loss: {:3.6f} \".format(epoch + 1, n_epoch,\n",
    "                                                                              train_acc / len(train_set),\n",
    "                                                                              train_loss / len(train_loader)))\n",
    "\n",
    "    if len(val_set) == 0:  #假设没有划分验证集。那最后保存的模型就是跑完最后一趟的epoch的模型\n",
    "        torch.save(model.state_dict(), config['model_path'])\n",
    "        print(\"saving model at last epoch\")\n",
    "    '''释放内存，回收资源'''\n",
    "    del train_loader, val_loader\n",
    "    gc.collect()\n"
   ],
   "id": "143b132dacaed6c9",
   "outputs": [],
   "execution_count": 233
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T10:41:39.354276Z",
     "start_time": "2025-03-22T10:41:32.369668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''训练准备'''\n",
    "set_seed(config['seed'])\n",
    "train_x, train_y = preprocess_data(split='train', feat_dir='./libriphone/feat', phone_path='./libriphone',\n",
    "                                   concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
    "val_x, val_y = preprocess_data(split='val', feat_dir='./libriphone/feat', phone_path='./libriphone',\n",
    "                               concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
    "\n",
    "train_set = LibriDataset(train_x, train_y)\n",
    "val_set = LibriDataset(val_x, val_y)\n",
    "\n",
    "del train_x, train_y, val_x, val_y\n",
    "gc.collect()\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_set, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n"
   ],
   "id": "13fe76cf13f16255",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] - # phone classes: 41, number of utterances for train: 2743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_23740\\3898882972.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  features = torch.load(path)\n",
      "2743it [00:05, 542.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train set\n",
      "torch.Size([1692441, 117])\n",
      "torch.Size([1692441])\n",
      "[Dataset] - # phone classes: 41, number of utterances for val: 686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "686it [00:01, 574.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val set\n",
      "torch.Size([424353, 117])\n",
      "torch.Size([424353])\n"
     ]
    }
   ],
   "execution_count": 234
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T10:44:53.482851Z",
     "start_time": "2025-03-22T10:41:39.403962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''开始训练'''\n",
    "print(f'DEVICE: {device}')\n",
    "model = Classifier(input_dim=input_dim, hidden_dim=256, hidden_layers=hidden_layers).to(device)\n",
    "train_process(train_set, val_set, train_dataloader, val_dataloader, config, model, device)\n"
   ],
   "id": "32b05d4076d6ba82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3306/3306 [00:33<00:00, 99.68it/s] \n",
      "100%|██████████| 829/829 [00:05<00:00, 138.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/005] Train Acc : 0.443827 Loss: 1.964963 | Val Acc: 0.476436 loss : 1.805017\n",
      "saving model with acc:61.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3306/3306 [00:39<00:00, 83.61it/s] \n",
      "100%|██████████| 829/829 [00:06<00:00, 123.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[002/005] Train Acc : 0.493030 Loss: 1.742287 | Val Acc: 0.499207 loss : 1.714210\n",
      "saving model with acc:64.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3306/3306 [00:34<00:00, 95.43it/s] \n",
      "100%|██████████| 829/829 [00:07<00:00, 117.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[003/005] Train Acc : 0.510005 Loss: 1.670788 | Val Acc: 0.509632 loss : 1.662607\n",
      "saving model with acc:65.4156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3306/3306 [00:33<00:00, 99.04it/s] \n",
      "100%|██████████| 829/829 [00:04<00:00, 173.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[004/005] Train Acc : 0.520666 Loss: 1.623920 | Val Acc: 0.517296 loss : 1.629743\n",
      "saving model with acc:66.3993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3306/3306 [00:23<00:00, 138.36it/s]\n",
      "100%|██████████| 829/829 [00:04<00:00, 174.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[005/005] Train Acc : 0.528172 Loss: 1.590537 | Val Acc: 0.524408 loss : 1.600099\n",
      "saving model with acc:67.3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 235
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T10:45:00.539721Z",
     "start_time": "2025-03-22T10:44:53.508622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''test预测'''\n",
    "\n",
    "\n",
    "def predict(model, test_loader):\n",
    "    test_acc = 0.0\n",
    "    test_length = 0.0\n",
    "    pred = np.array([], dtype=np.int32)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(test_loader)):\n",
    "            features = batch\n",
    "            features = features.to(device)\n",
    "            outputs = model(features)\n",
    "\n",
    "            _, test_pred = torch.max(outputs, dim=1)\n",
    "\n",
    "            pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "'''保存预测结果'''\n",
    "\n",
    "\n",
    "def save_pred(preds, file):\n",
    "    with open(file, 'w') as f:\n",
    "        f.write('Id,Class\\n')\n",
    "        for i, y in enumerate(preds):\n",
    "            f.write('{},{}\\n'.format(i, y))\n",
    "\n",
    "\n",
    "test_x = preprocess_data(split='test', feat_dir='./libriphone/feat', phone_path='./libriphone',\n",
    "                         concat_nframes=concat_nframes)\n",
    "test_set = LibriDataset(test_x, None)\n",
    "test_loader = DataLoader(test_set, batch_size=config['batch_size'], shuffle=False, pin_memory=True)\n",
    "\n",
    "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers).to(device)\n",
    "model.load_state_dict(torch.load(config['model_path']))\n",
    "\n",
    "preds = predict(model, test_loader)\n",
    "save_pred(preds, 'prediction.csv')"
   ],
   "id": "809ca207ee648685",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] - # phone classes: 41, number of utterances for test: 857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_23740\\3898882972.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  features = torch.load(path)\n",
      "857it [00:01, 582.22it/s]\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_23740\\3134385920.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(config['model_path']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test set\n",
      "torch.Size([527364, 117])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1031/1031 [00:05<00:00, 201.84it/s]\n"
     ]
    }
   ],
   "execution_count": 236
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
